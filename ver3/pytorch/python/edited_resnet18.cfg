[net]
batch=1
subdivisions=1
max_batches=1
momentum=0.9
decay=0.00005
policy=poly
power=4
learning_rate=0.01
angle==1
hue==1
saturation=1
exposure=1
aspect=1
height=32
width=32
channels=3
quantization_type=1
start_check_point=0
end_check_point=0
input_scale=0.03739064
input_zeropoint=57
normalize_mean_0=0.485
normalize_mean_1=0.456
normalize_mean_2=0.406
normalize_var_0=0.229
normalize_var_1=0.224
normalize_var_2=0.225

[convolutional]
quantization_type=1
quantization_layer_scale=0.05000000074505806
quantization_layer_zeropoint=0
filters=64
size=7
pad=3
stride=2
activation=relu

[maxpool]
quantization_type=1
quantization_layer_scale=0.05000000074505806
quantization_layer_zeropoint=0
size=3
pad=1
stride=2

[convolutional]
quantization_type=1
quantization_layer_scale=0.0312686413526535
quantization_layer_zeropoint=0
filters=64
size=3
pad=1
stride=1
activation=relu

[convolutional]
quantization_type=1
quantization_layer_scale=0.05000000074505806
quantization_layer_zeropoint=0
filters=64
size=3
pad=1
stride=1
activation=relu

[shortcut]
quantization_type=1
quantization_layer_scale=0.05000000074505806
quantization_layer_zeropoint=0
from=-3

[convolutional]
quantization_type=1
quantization_layer_scale=0.024647517129778862
quantization_layer_zeropoint=0
filters=64
size=3
pad=1
stride=1
activation=relu

[convolutional]
quantization_type=1
quantization_layer_scale=0.05000000074505806
quantization_layer_zeropoint=0
filters=64
size=3
pad=1
stride=1
activation=relu

[shortcut]
quantization_type=1
quantization_layer_scale=0.05000000074505806
quantization_layer_zeropoint=0
from=-3

[convolutional]
quantization_type=1
quantization_layer_scale=0.02416195161640644
quantization_layer_zeropoint=0
filters=128
size=3
pad=1
stride=2
activation=relu

[convolutional]
quantization_type=1
quantization_layer_scale=0.05000000074505806
quantization_layer_zeropoint=0
filters=128
size=3
pad=1
stride=1
activation=relu

[shortcut]
quantization_type=1
quantization_layer_scale=0.05000000074505806
quantization_layer_zeropoint=0
from=-3

[convolutional]
quantization_type=1
quantization_layer_scale=0.02010982111096382
quantization_layer_zeropoint=0
filters=128
size=3
pad=1
stride=1
activation=relu

[convolutional]
quantization_type=1
quantization_layer_scale=0.05000000074505806
quantization_layer_zeropoint=0
filters=128
size=3
pad=1
stride=1
activation=relu

[shortcut]
quantization_type=1
quantization_layer_scale=0.05000000074505806
quantization_layer_zeropoint=0
from=-3

[convolutional]
quantization_type=1
quantization_layer_scale=0.021660206839442253
quantization_layer_zeropoint=0
filters=256
size=3
pad=1
stride=2
activation=relu

[convolutional]
quantization_type=1
quantization_layer_scale=0.05000000074505806
quantization_layer_zeropoint=0
filters=256
size=3
pad=1
stride=1
activation=relu

[shortcut]
quantization_type=1
quantization_layer_scale=0.05000000074505806
quantization_layer_zeropoint=0
from=-3

[convolutional]
quantization_type=1
quantization_layer_scale=0.006181688979268074
quantization_layer_zeropoint=0
filters=256
size=3
pad=1
stride=1
activation=relu

[convolutional]
quantization_type=1
quantization_layer_scale=0.05000000074505806
quantization_layer_zeropoint=0
filters=256
size=3
pad=1
stride=1
activation=relu

[shortcut]
quantization_type=1
quantization_layer_scale=0.05000000074505806
quantization_layer_zeropoint=0
from=-3

[convolutional]
quantization_type=1
quantization_layer_scale=0.007224411703646183
quantization_layer_zeropoint=0
filters=512
size=3
pad=1
stride=2
activation=relu

[convolutional]
quantization_type=1
quantization_layer_scale=0.05000000074505806
quantization_layer_zeropoint=0
filters=512
size=3
pad=1
stride=1
activation=relu

[shortcut]
quantization_type=1
quantization_layer_scale=0.05000000074505806
quantization_layer_zeropoint=0
from=-3

[convolutional]
quantization_type=1
quantization_layer_scale=0.003084570402279496
quantization_layer_zeropoint=0
filters=512
size=3
pad=1
stride=1
activation=relu

[convolutional]
quantization_type=1
quantization_layer_scale=0.05000000074505806
quantization_layer_zeropoint=0
filters=512
size=3
pad=1
stride=1
activation=relu

[shortcut]
quantization_type=1
quantization_layer_scale=0.05000000074505806
quantization_layer_zeropoint=0
from=-3

[connected]
quantization_type=1
quantization_layer_scale=0.2766161859035492
quantization_layer_zeropoint=0
output=10
activation=linear

[softmax]
groups=1
quantization_type=1
