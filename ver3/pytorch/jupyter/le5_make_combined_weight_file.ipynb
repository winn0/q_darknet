{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdc7df82",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########load mnist saved model\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "sys.path.append(\"..\")\n",
    "from module.lenet5_module import *\n",
    "from module.extract_weight_module import *\n",
    "model_dir = os.getcwd()+'/saved_models'\n",
    "model_filename='le5_saved.pt'\n",
    "model_filepath=model_dir+'/'+model_filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fb85d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\win0\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\ao\\quantization\\observer.py:174: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  reduce_range will be deprecated in a future release of PyTorch.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0723, Accuracy: 9783/10000 (98%)\n",
      "\n",
      "inference를 할 때 걸린 시간(secs): 7.42032527923584\n"
     ]
    }
   ],
   "source": [
    "###########fusionx load model\n",
    "\n",
    "model_dir = os.getcwd()+'/saved_models'\n",
    "model_filename='le5.pt'\n",
    "model_filepath=model_dir+'/'+'le5.pt'\n",
    "transform = transforms.Compose([\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "dataset1 = datasets.MNIST('../data', train=True, download=True,\n",
    "                              transform = transform)\n",
    "dataset2 = datasets.MNIST('../data', train=False, download=True,\n",
    "                              transform = transform)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset1, batch_size=64)\n",
    "test_loader = torch.utils.data.DataLoader(dataset2, batch_size=1)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model_fp32 = Net()\n",
    "model_fp32.train() # 아래에 진행될 Quantization Aware Training logic이 작동하기 위해서는 모델을 train 모드로 바꿔줘야 한다고 한다.\n",
    "model_fp32.qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')\n",
    "#model_fp32_fused = torch.quantization.fuse_modules(model_fp32, [['conv1', 'relu']])\n",
    "model_fp32_prepared = torch.quantization.prepare_qat(model_fp32)\n",
    "model_fp32_prepared = model_fp32_prepared.to(\"cuda\")\n",
    "model_fp32_prepared = load_model(model=model_fp32_prepared, model_filepath=model_filepath, device='cpu')\n",
    "\n",
    "model_fp32_prepared.eval()\n",
    "model_int8_unfused = torch.quantization.convert(model_fp32_prepared.to('cpu')) #quantized aware training을 floating point로 수행한 model을 quantized integer model로 바꿔준다.\n",
    "\n",
    "\n",
    "\n",
    "model_int8_unfused.eval()\n",
    "\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "start2 = time.time()   \n",
    "count =0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to('cpu'), target.to('cpu') #GPU는 integer형 연산을 지원하지 않으므로 추론 속도를 비교하기 위해서 모델과 data를 모두 cpu로 옮겨줬다.\n",
    "        output = model_int8_unfused(data)\n",
    "        input_data =data\n",
    "        test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "\n",
    "\n",
    "print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)\n",
    "))\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "\n",
    "#print(\"test 이전까지 경과 시간(secs):\",start2-start)\n",
    "print(\"inference를 할 때 걸린 시간(secs):\",end-start2)\n",
    "#print(\"total time elapsed(secs):\", (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94915b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quant.scale\n",
      "quant.zero_point\n",
      "conv1.weight\n",
      "conv1.bias\n",
      "conv1.scale\n",
      "conv1.zero_point\n",
      "conv2.weight\n",
      "conv2.bias\n",
      "conv2.scale\n",
      "conv2.zero_point\n",
      "fc1.scale\n",
      "fc1.zero_point\n",
      "fc1._packed_params.dtype\n",
      "fc1._packed_params._packed_params\n",
      "fc2.scale\n",
      "fc2.zero_point\n",
      "fc2._packed_params.dtype\n",
      "fc2._packed_params._packed_params\n",
      "quant.scale\n",
      "quant.zero_point\n",
      "conv1.weight\n",
      "32\n",
      "[0.00090746]\n",
      "[0.00102427]\n",
      "[0.0010331]\n",
      "[0.00093175]\n",
      "[0.00097007]\n",
      "[0.00077535]\n",
      "[0.00090093]\n",
      "[0.00080656]\n",
      "[0.00100204]\n",
      "[0.00089431]\n",
      "[0.0006309]\n",
      "[0.00101965]\n",
      "[0.0007286]\n",
      "[0.00086691]\n",
      "[0.00102678]\n",
      "[0.00088749]\n",
      "[0.00091408]\n",
      "[0.00091872]\n",
      "[0.00091154]\n",
      "[0.00098385]\n",
      "[0.00097964]\n",
      "[0.00103721]\n",
      "[0.00104833]\n",
      "[0.00093265]\n",
      "[0.00084486]\n",
      "[0.00083738]\n",
      "[0.00091157]\n",
      "[0.00056241]\n",
      "[0.00102831]\n",
      "[0.0010281]\n",
      "[0.00086156]\n",
      "[0.00099975]\n",
      "conv1.bias\n",
      "conv1.scale\n",
      "conv1.zero_point\n",
      "conv2.weight\n",
      "64\n",
      "0.000274472988122347\n",
      "0.0002645808373649315\n",
      "0.0003015659246962644\n",
      "0.00026960872112900445\n",
      "0.00028212985166272244\n",
      "0.00026690459683910824\n",
      "0.00027649071864478973\n",
      "0.0002824277342184032\n",
      "0.0002610771383124161\n",
      "0.0002903655286226723\n",
      "0.00032781022843133043\n",
      "0.00027880267782468346\n",
      "0.0002801911591519871\n",
      "0.00027228250608359955\n",
      "0.00027822140850629893\n",
      "0.0002685951237700757\n",
      "0.0003042778359823879\n",
      "0.0002977801267304213\n",
      "0.000278353817392149\n",
      "0.00026772618484106236\n",
      "0.0002864733183583842\n",
      "0.00031035205243952984\n",
      "0.00030694107854209067\n",
      "0.00028689836855245435\n",
      "0.0002777869240667995\n",
      "0.00029424803509166167\n",
      "0.0002766834468014161\n",
      "0.0002735116834380833\n",
      "0.0002922515690589166\n",
      "0.00030361270670463213\n",
      "0.0002918059731748005\n",
      "0.00024047750834259838\n",
      "0.0002950452737554126\n",
      "0.0002796762889514332\n",
      "0.00024987855421294613\n",
      "0.00026708929839962335\n",
      "0.0002898039364447544\n",
      "0.00023622735082672988\n",
      "0.0003030954405052391\n",
      "0.0002896422963730664\n",
      "0.00028732674319491383\n",
      "0.00029704859833483476\n",
      "0.000279865003810004\n",
      "0.00023749751473635633\n",
      "0.0002910211038550568\n",
      "0.00025954612500416694\n",
      "0.0002606309434285902\n",
      "0.0002891752862493251\n",
      "0.00026411622324002944\n",
      "0.000280449417876865\n",
      "0.0002911573163890641\n",
      "0.0002869309840866526\n",
      "0.00028012272343514306\n",
      "0.0002969878897142471\n",
      "0.000255137517090065\n",
      "0.0003115692198498322\n",
      "0.00029779045947541527\n",
      "0.0002473713960026231\n",
      "0.00027973088777498103\n",
      "0.00028244923830798483\n",
      "0.00028856724164391277\n",
      "0.0002995437016759982\n",
      "0.00026100564769705216\n",
      "0.00025174783763230903\n",
      "conv2.bias\n",
      "conv2.scale\n",
      "conv2.zero_point\n",
      "fc1.scale\n",
      "fc1.zero_point\n",
      "fc1._packed_params.dtype\n",
      "fc1._packed_params._packed_params\n",
      "128\n",
      "9.75992907345006e-05\n",
      "0.00010361113665514488\n",
      "0.00010663470558351847\n",
      "9.2721371414179e-05\n",
      "9.676208808011084e-05\n",
      "8.903722931359797e-05\n",
      "0.0001042013583153234\n",
      "9.959089449557208e-05\n",
      "0.00010200167601581581\n",
      "8.339469308338595e-05\n",
      "0.00010232311950980157\n",
      "9.098747296317684e-05\n",
      "9.267323710983605e-05\n",
      "0.00010038573610232248\n",
      "8.943296550569047e-05\n",
      "8.447997597436242e-05\n",
      "9.411948259873525e-05\n",
      "8.469925248594033e-05\n",
      "8.800165362662364e-05\n",
      "9.297917503047702e-05\n",
      "9.99748339402207e-05\n",
      "9.383621766920421e-05\n",
      "7.20091650626264e-05\n",
      "8.539571636855275e-05\n",
      "9.483862840938748e-05\n",
      "9.88148115046434e-05\n",
      "5.787707719210709e-05\n",
      "9.65131945829049e-05\n",
      "9.882457063207424e-05\n",
      "9.892151844743116e-05\n",
      "0.00011123427528574399\n",
      "0.00010503625524180369\n",
      "6.603648523718877e-05\n",
      "9.672354310153097e-05\n",
      "0.00010083385164045177\n",
      "7.392547518944437e-05\n",
      "8.33179069818422e-05\n",
      "9.753703608094453e-05\n",
      "8.480532490670648e-05\n",
      "0.00010814473394098352\n",
      "0.00011042559931153666\n",
      "9.74986698409623e-05\n",
      "0.00010003248607488769\n",
      "5.6358161057874677e-05\n",
      "8.410819075435293e-05\n",
      "8.177653681128196e-05\n",
      "5.631815935972409e-05\n",
      "9.660402060129283e-05\n",
      "0.00010218786801297159\n",
      "9.380639513418891e-05\n",
      "0.00010178037082115474\n",
      "9.49531730396815e-05\n",
      "6.532414936710641e-05\n",
      "7.84023363759289e-05\n",
      "8.527929498298358e-05\n",
      "8.420155486082728e-05\n",
      "9.20799500827081e-05\n",
      "0.0001039045271262319\n",
      "9.696516193781318e-05\n",
      "7.270043658897754e-05\n",
      "8.654684655889775e-05\n",
      "0.00010218315825092393\n",
      "9.246726768685202e-05\n",
      "7.553024840905048e-05\n",
      "0.00010735338667381687\n",
      "9.819691217262119e-05\n",
      "8.73382027629943e-05\n",
      "0.0001018961219369828\n",
      "9.579165367504436e-05\n",
      "5.640314062596938e-05\n",
      "0.00010064024199149414\n",
      "8.144158961624493e-05\n",
      "9.436772370005983e-05\n",
      "8.86404028160599e-05\n",
      "9.5652729100033e-05\n",
      "9.677808518459911e-05\n",
      "8.940316978146482e-05\n",
      "8.128854469202045e-05\n",
      "9.365406516435497e-05\n",
      "8.725079958875105e-05\n",
      "8.014376865882136e-05\n",
      "9.506295428634857e-05\n",
      "9.71837503057902e-05\n",
      "5.588612582691698e-05\n",
      "9.021049627925999e-05\n",
      "8.289996251899362e-05\n",
      "9.904356116189594e-05\n",
      "0.00010741337134718298\n",
      "0.00010251289521583992\n",
      "8.146453965218118e-05\n",
      "8.763432793462513e-05\n",
      "9.650579480496282e-05\n",
      "5.5908606674034455e-05\n",
      "8.824298648114964e-05\n",
      "9.8733842919915e-05\n",
      "8.580696707091992e-05\n",
      "0.00010463786478153632\n",
      "0.00010417586125437085\n",
      "9.715105007935298e-05\n",
      "7.602001897735846e-05\n",
      "9.6424254256722e-05\n",
      "0.0001034531585456257\n",
      "0.00010305080008849083\n",
      "9.934805129989606e-05\n",
      "9.565297039713981e-05\n",
      "5.580528235920693e-05\n",
      "8.316597917385293e-05\n",
      "9.401027331558062e-05\n",
      "8.845877759007368e-05\n",
      "0.00010398697924132067\n",
      "9.680056156325164e-05\n",
      "9.730711568587749e-05\n",
      "0.00010633055504885386\n",
      "0.00010864596165339986\n",
      "5.575211209487563e-05\n",
      "8.965161643217666e-05\n",
      "7.592153401006189e-05\n",
      "9.191842401202587e-05\n",
      "0.00010674799904362906\n",
      "6.595642821930831e-05\n",
      "0.0001130376762404363\n",
      "0.0001124227529060647\n",
      "8.905410223721467e-05\n",
      "8.565551292021439e-05\n",
      "9.373584700970259e-05\n",
      "9.904300707224327e-05\n",
      "5.539907208529305e-05\n",
      "8.562229435184403e-05\n",
      "fc2.scale\n",
      "fc2.zero_point\n",
      "fc2._packed_params.dtype\n",
      "fc2._packed_params._packed_params\n",
      "10\n",
      "0.0007344394798047604\n",
      "0.0009458645342754661\n",
      "0.0010006907609609113\n",
      "0.0011811857077154277\n",
      "0.0010205481947144922\n",
      "0.0010255608076581424\n",
      "0.0008605452555669345\n",
      "0.0010338925715037137\n",
      "0.001031203656971552\n",
      "0.001049848764053779\n"
     ]
    }
   ],
   "source": [
    "extract_model=model_int8_unfused\n",
    "\n",
    "SCALE='scale'\n",
    "WEIGHT='weight'\n",
    "BIAS='bias'\n",
    "FC='_packed_params'\n",
    "save_list= dict()\n",
    "save_list=make_default_save_file(save_list)\n",
    "scale_list=list()\n",
    "weight_input_scale_index_dict=dict()\n",
    "weight_dict=dict()\n",
    "weight_channel_scale_dict=dict()\n",
    "weight_channel_zeropoint_dict=dict()\n",
    "weight_channel_bias_dict=dict()\n",
    "scale_count=-1\n",
    "for parameter_name in extract_model.state_dict():\n",
    "    print(parameter_name)\n",
    "    if parameter_name[-len(SCALE):]==SCALE:\n",
    "        scale_count+=1\n",
    "        scale_list.append(extract_model.state_dict()[parameter_name].numpy())\n",
    "    if parameter_name[-len(WEIGHT):]==WEIGHT:\n",
    "        file_name=parameter_name[:-len(WEIGHT)-1]\n",
    "        weight_input_scale_index_dict[file_name]=scale_count\n",
    "        weight_dict[file_name]=extract_model.state_dict()[parameter_name].int_repr().numpy().flatten()\n",
    "        weight_channel_scale_dict[file_name]=extract_model.state_dict()[parameter_name].q_per_channel_scales().numpy()\n",
    "        weight_channel_zeropoint_dict[file_name]=extract_model.state_dict()[parameter_name].q_per_channel_zero_points().numpy()\n",
    "    if parameter_name[-len(BIAS):]==BIAS:\n",
    "        weight_channel_bias_dict[file_name]=extract_model.state_dict()[parameter_name].detach().numpy()\n",
    "    if parameter_name[-len(FC):]==FC:\n",
    "        file_name=parameter_name[:-len(FC)-1]\n",
    "        weight_input_scale_index_dict[file_name]=scale_count-1 #fc layer scale is faster than weight\n",
    "        weight_dict[file_name]=extract_model.state_dict()[parameter_name][0].int_repr().numpy().flatten()\n",
    "        weight_channel_scale_dict[file_name]=extract_model.state_dict()[parameter_name][0].q_per_channel_scales().numpy()\n",
    "        weight_channel_zeropoint_dict[file_name]=extract_model.state_dict()[parameter_name][0].q_per_channel_zero_points().numpy()\n",
    "        weight_channel_bias_dict[file_name]=extract_model.state_dict()[parameter_name][1].detach().numpy()\n",
    "        \n",
    "for parameter_name in extract_model.state_dict():\n",
    "    print(parameter_name)\n",
    "    if parameter_name[-len(WEIGHT):]==WEIGHT:\n",
    "        file_name=parameter_name[:-len(WEIGHT)-1]\n",
    "        M_in32_np, right_shift_np, bias_int32_np =make_channel_nomalization(scale_list[weight_input_scale_index_dict[file_name]], weight_channel_scale_dict[file_name],\n",
    "                                 scale_list[weight_input_scale_index_dict[file_name]+1],weight_channel_bias_dict[file_name])\n",
    "        save_np_file=weight_dict[file_name]\n",
    "        save_list=save_np_1darray(save_list,file_name+\"_weight\",save_np_file)\n",
    "        save_np_file=M_in32_np\n",
    "        save_list=save_np_1darray(save_list,file_name+\"_M0\",save_np_file)\n",
    "        save_np_file=right_shift_np\n",
    "        save_list=save_np_1darray(save_list,file_name+\"_rightshift\",save_np_file)\n",
    "        save_np_file=weight_channel_zeropoint_dict[file_name]\n",
    "        save_list=save_np_1darray(save_list,file_name+\"_zeropoint\",save_np_file)\n",
    "        save_np_file=bias_int32_np\n",
    "        save_list=save_np_1darray(save_list,file_name+\"_bias_int32\",save_np_file)\n",
    "        save_np_file=weight_channel_scale_dict[file_name]\n",
    "        save_list=save_np_1darray(save_list,file_name+\"_scale\",save_np_file)\n",
    "        save_np_file=weight_channel_bias_dict[file_name]\n",
    "        save_list=save_np_1darray(save_list,file_name+\"_bias_float32\",save_np_file)\n",
    "    if parameter_name[-len(FC):]==FC:\n",
    "        file_name=parameter_name[:-len(FC)-1]\n",
    "        M_in32_np, right_shift_np, bias_int32_np =make_channel_nomalization(scale_list[weight_input_scale_index_dict[file_name]], weight_channel_scale_dict[file_name],\n",
    "                                 scale_list[weight_input_scale_index_dict[file_name]+1],weight_channel_bias_dict[file_name])\n",
    "        save_np_file=weight_dict[file_name]\n",
    "        save_list=save_np_1darray(save_list,file_name+\"_weight\",save_np_file)\n",
    "        save_np_file=M_in32_np\n",
    "        save_list=save_np_1darray(save_list,file_name+\"_M0\",save_np_file)\n",
    "        save_np_file=right_shift_np\n",
    "        save_list=save_np_1darray(save_list,file_name+\"_rightshift\",save_np_file)\n",
    "        save_np_file=weight_channel_zeropoint_dict[file_name]\n",
    "        save_list=save_np_1darray(save_list,file_name+\"_zeropoint\",save_np_file)\n",
    "        save_np_file=bias_int32_np\n",
    "        save_list=save_np_1darray(save_list,file_name+\"_bias_int32\",save_np_file)\n",
    "        save_np_file=weight_channel_scale_dict[file_name]\n",
    "        save_list=save_np_1darray(save_list,file_name+\"_scale\",save_np_file)\n",
    "        save_np_file=weight_channel_bias_dict[file_name]\n",
    "        save_list=save_np_1darray(save_list,file_name+\"_bias_float32\",save_np_file)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91697239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default_setting   data size: 16 byte\n",
      "conv1_weight   data size: 288 byte\n",
      "conv1_M0   data size: 128 byte\n",
      "conv1_rightshift   data size: 32 byte\n",
      "conv1_zeropoint   data size: 128 byte\n",
      "conv1_bias_int32   data size: 128 byte\n",
      "conv1_scale   data size: 128 byte\n",
      "conv1_bias_float32   data size: 128 byte\n",
      "conv2_weight   data size: 18432 byte\n",
      "conv2_M0   data size: 256 byte\n",
      "conv2_rightshift   data size: 64 byte\n",
      "conv2_zeropoint   data size: 256 byte\n",
      "conv2_bias_int32   data size: 256 byte\n",
      "conv2_scale   data size: 256 byte\n",
      "conv2_bias_float32   data size: 256 byte\n",
      "fc1._packed_params_weight   data size: 991232 byte\n",
      "fc1._packed_params_M0   data size: 512 byte\n",
      "fc1._packed_params_rightshift   data size: 128 byte\n",
      "fc1._packed_params_zeropoint   data size: 512 byte\n",
      "fc1._packed_params_bias_int32   data size: 512 byte\n",
      "fc1._packed_params_scale   data size: 512 byte\n",
      "fc1._packed_params_bias_float32   data size: 512 byte\n",
      "fc2._packed_params_weight   data size: 1280 byte\n",
      "fc2._packed_params_M0   data size: 40 byte\n",
      "fc2._packed_params_rightshift   data size: 10 byte\n",
      "fc2._packed_params_zeropoint   data size: 40 byte\n",
      "fc2._packed_params_bias_int32   data size: 40 byte\n",
      "fc2._packed_params_scale   data size: 40 byte\n",
      "fc2._packed_params_bias_float32   data size: 40 byte\n"
     ]
    }
   ],
   "source": [
    "#saved layer info\n",
    "for name in save_list:\n",
    "    print(name, \"  data size:\",save_list[name], \"byte\")\n",
    "#merge weights\n",
    "merge_weight_files(save_list,\"le5_mnist_weights_combined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ad91a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
