{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af733340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model.model_fp32.conv1': [['0', '1', '2']], 'model.model_fp32.conv2_x[0].residual_function': [['0', '1', '2'], ['3', '4', '5']], 'model.model_fp32.conv2_x[1].residual_function': [['0', '1', '2'], ['3', '4', '5']], 'model.model_fp32.conv3_x[0].residual_function': [['0', '1', '2'], ['3', '4', '5']], 'model.model_fp32.conv3_x[0].shortcut': [['0', '1', '2']], 'model.model_fp32.conv3_x[1].residual_function': [['0', '1', '2'], ['3', '4', '5']], 'model.model_fp32.conv4_x[0].residual_function': [['0', '1', '2'], ['3', '4', '5']], 'model.model_fp32.conv4_x[0].shortcut': [['0', '1', '2']], 'model.model_fp32.conv4_x[1].residual_function': [['0', '1', '2'], ['3', '4', '5']], 'model.model_fp32.conv5_x[0].residual_function': [['0', '1', '2'], ['3', '4', '5']], 'model.model_fp32.conv5_x[0].shortcut': [['0', '1', '2']], 'model.model_fp32.conv5_x[1].residual_function': [['0', '1', '2'], ['3', '4', '5']]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\win0\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\ao\\quantization\\observer.py:174: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  reduce_range will be deprecated in a future release of PyTorch.\"\n",
      "C:\\Users\\win0\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\ao\\quantization\\observer.py:1109: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  Returning default scale and zero point \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QuantizedResNet18(\n",
       "  (quant): Quantize(scale=tensor([0.0374]), zero_point=tensor([57]), dtype=torch.quint8)\n",
       "  (dequant): DeQuantize()\n",
       "  (model_fp32): ResNet(\n",
       "    (conv1): Sequential(\n",
       "      (0): QuantizedConvReLU2d(3, 64, kernel_size=(7, 7), stride=(2, 2), scale=0.05000000074505806, zero_point=0, padding=(3, 3))\n",
       "      (1): Identity()\n",
       "      (2): Identity()\n",
       "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv2_x): Sequential(\n",
       "      (0): q_BasicBlock(\n",
       "        (residual_function): Sequential(\n",
       "          (0): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.0312686413526535, zero_point=0, padding=(1, 1))\n",
       "          (1): Identity()\n",
       "          (2): Identity()\n",
       "          (3): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.05000000074505806, zero_point=0, padding=(1, 1))\n",
       "          (4): Identity()\n",
       "          (5): Identity()\n",
       "        )\n",
       "        (shortcut): Sequential()\n",
       "        (q_func): QFunctional(\n",
       "          scale=0.05000000074505806, zero_point=0\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): q_BasicBlock(\n",
       "        (residual_function): Sequential(\n",
       "          (0): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.024647517129778862, zero_point=0, padding=(1, 1))\n",
       "          (1): Identity()\n",
       "          (2): Identity()\n",
       "          (3): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.05000000074505806, zero_point=0, padding=(1, 1))\n",
       "          (4): Identity()\n",
       "          (5): Identity()\n",
       "        )\n",
       "        (shortcut): Sequential()\n",
       "        (q_func): QFunctional(\n",
       "          scale=0.05000000074505806, zero_point=0\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (conv3_x): Sequential(\n",
       "      (0): q_BasicBlock(\n",
       "        (residual_function): Sequential(\n",
       "          (0): QuantizedConvReLU2d(64, 128, kernel_size=(3, 3), stride=(2, 2), scale=0.02416195161640644, zero_point=0, padding=(1, 1))\n",
       "          (1): Identity()\n",
       "          (2): Identity()\n",
       "          (3): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.05000000074505806, zero_point=0, padding=(1, 1))\n",
       "          (4): Identity()\n",
       "          (5): Identity()\n",
       "        )\n",
       "        (shortcut): Sequential(\n",
       "          (0): QuantizedConvReLU2d(64, 128, kernel_size=(1, 1), stride=(2, 2), scale=0.05000000074505806, zero_point=0)\n",
       "          (1): Identity()\n",
       "          (2): Identity()\n",
       "        )\n",
       "        (q_func): QFunctional(\n",
       "          scale=0.05000000074505806, zero_point=0\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): q_BasicBlock(\n",
       "        (residual_function): Sequential(\n",
       "          (0): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.02010982111096382, zero_point=0, padding=(1, 1))\n",
       "          (1): Identity()\n",
       "          (2): Identity()\n",
       "          (3): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.05000000074505806, zero_point=0, padding=(1, 1))\n",
       "          (4): Identity()\n",
       "          (5): Identity()\n",
       "        )\n",
       "        (shortcut): Sequential()\n",
       "        (q_func): QFunctional(\n",
       "          scale=0.05000000074505806, zero_point=0\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (conv4_x): Sequential(\n",
       "      (0): q_BasicBlock(\n",
       "        (residual_function): Sequential(\n",
       "          (0): QuantizedConvReLU2d(128, 256, kernel_size=(3, 3), stride=(2, 2), scale=0.021660206839442253, zero_point=0, padding=(1, 1))\n",
       "          (1): Identity()\n",
       "          (2): Identity()\n",
       "          (3): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.05000000074505806, zero_point=0, padding=(1, 1))\n",
       "          (4): Identity()\n",
       "          (5): Identity()\n",
       "        )\n",
       "        (shortcut): Sequential(\n",
       "          (0): QuantizedConvReLU2d(128, 256, kernel_size=(1, 1), stride=(2, 2), scale=0.05000000074505806, zero_point=0)\n",
       "          (1): Identity()\n",
       "          (2): Identity()\n",
       "        )\n",
       "        (q_func): QFunctional(\n",
       "          scale=0.05000000074505806, zero_point=0\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): q_BasicBlock(\n",
       "        (residual_function): Sequential(\n",
       "          (0): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.006181688979268074, zero_point=0, padding=(1, 1))\n",
       "          (1): Identity()\n",
       "          (2): Identity()\n",
       "          (3): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.05000000074505806, zero_point=0, padding=(1, 1))\n",
       "          (4): Identity()\n",
       "          (5): Identity()\n",
       "        )\n",
       "        (shortcut): Sequential()\n",
       "        (q_func): QFunctional(\n",
       "          scale=0.05000000074505806, zero_point=0\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (conv5_x): Sequential(\n",
       "      (0): q_BasicBlock(\n",
       "        (residual_function): Sequential(\n",
       "          (0): QuantizedConvReLU2d(256, 512, kernel_size=(3, 3), stride=(2, 2), scale=0.007224411703646183, zero_point=0, padding=(1, 1))\n",
       "          (1): Identity()\n",
       "          (2): Identity()\n",
       "          (3): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.05000000074505806, zero_point=0, padding=(1, 1))\n",
       "          (4): Identity()\n",
       "          (5): Identity()\n",
       "        )\n",
       "        (shortcut): Sequential(\n",
       "          (0): QuantizedConvReLU2d(256, 512, kernel_size=(1, 1), stride=(2, 2), scale=0.05000000074505806, zero_point=0)\n",
       "          (1): Identity()\n",
       "          (2): Identity()\n",
       "        )\n",
       "        (q_func): QFunctional(\n",
       "          scale=0.05000000074505806, zero_point=0\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): q_BasicBlock(\n",
       "        (residual_function): Sequential(\n",
       "          (0): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.003084570402279496, zero_point=0, padding=(1, 1))\n",
       "          (1): Identity()\n",
       "          (2): Identity()\n",
       "          (3): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.05000000074505806, zero_point=0, padding=(1, 1))\n",
       "          (4): Identity()\n",
       "          (5): Identity()\n",
       "        )\n",
       "        (shortcut): Sequential()\n",
       "        (q_func): QFunctional(\n",
       "          scale=0.05000000074505806, zero_point=0\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): QuantizedLinear(in_features=512, out_features=10, scale=0.2766161859035492, zero_point=0, qscheme=torch.per_channel_affine)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####load quanztized_resnet18\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "sys.path.append(\"..\")\n",
    "from module.layer_fusion_module import *\n",
    "from module.resnet_module import *\n",
    "from module.extract_weight_module import *\n",
    "model_dir = \"saved_models\"\n",
    "model_filename = \"q_resnet18_cifar10.pt\"\n",
    "quantized_model_edited_filename = \"q_resnet18_quantized_cifar10_edited.pt\"\n",
    "fusioned_model_filename = \"q_fusioned_resnet18_cifar10.pt\"\n",
    "quantized_model_filename_jit = \"q_resnet18_quantized_cifar10.pt\"\n",
    "quantized_model_filename = \"q_resnet18_quantized_cifar10.pt\"\n",
    "\n",
    "model_filepath = os.path.join(model_dir, model_filename)\n",
    "quantized_model_filepath = os.path.join(model_dir, quantized_model_filename)\n",
    "quantized_model_filepath_jit = os.path.join(model_dir, quantized_model_filename_jit)\n",
    "quantized_model_edited_filepath = os.path.join(model_dir, quantized_model_edited_filename)\n",
    "\n",
    "num_classes = 10\n",
    "cuda_device = torch.device(\"cuda:0\")\n",
    "cpu_device = torch.device(\"cpu:0\")\n",
    "\n",
    "model = create_model(num_classes=num_classes)\n",
    "model.to(cpu_device)\n",
    "\n",
    "quantized_model = QuantizedResNet18(model_fp32=model)\n",
    "\n",
    "quantization_config = torch.quantization.get_default_qconfig(\"fbgemm\")\n",
    "\n",
    "quantized_model.qconfig = quantization_config\n",
    "fuse_model(quantized_model)\n",
    "torch.quantization.prepare_qat(quantized_model, inplace=True)\n",
    "quantized_model.to(cpu_device)    \n",
    "quantized_model = torch.quantization.convert(quantized_model, inplace=True)\n",
    "#save_torchscript_model(model=quantized_model, model_dir=model_dir, model_filename=quantized_model_filename_jit)\n",
    "#save_model(model=quantized_model, model_dir=model_dir, model_filename=quantized_model_filename)\n",
    "loaded_model=load_model(model=quantized_model, model_filepath=quantized_model_edited_filepath, device='cpu')\n",
    "loaded_model.eval()\n",
    "#save each layer weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68613ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = prepare_dataloader(num_workers=0, train_batch_size=1, eval_batch_size=1)\n",
    "count=0\n",
    "save_inputs_list=list()\n",
    "save_labels_list=list()\n",
    "for inputs, labels in test_loader:   \n",
    "\n",
    "    test_inputs = inputs.to(cpu_device)\n",
    "    test_labels = labels.to(cpu_device)\n",
    "test_input = torch.unsqueeze(test_inputs[0],0) \n",
    "test_labels=test_labels\n",
    "\n",
    "# test_input_1 = torch.unsqueeze(test_inputs[1],0) \n",
    "# test_input_2 = torch.unsqueeze(test_inputs[2],0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1590f965",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get individual output\n",
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "df0bef99",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model.model_fp32.fc.register_forward_hook(get_activation('fc'))\n",
    "quantized_model.quant.register_forward_hook(get_activation('quant'))\n",
    "quantized_model.model_fp32.conv1[0].register_forward_hook(get_activation('conv1'))\n",
    "quantized_model.model_fp32.conv2_x[0].register_forward_hook(get_activation('conv1'))\n",
    "quantized_model.model_fp32.conv2_x[0].residual_function[0].register_forward_hook(get_activation('2'))\n",
    "quantized_model.model_fp32.conv2_x[0].residual_function[3].register_forward_hook(get_activation('3'))\n",
    "quantized_model.model_fp32.conv2_x[0].relu.register_forward_hook(get_activation('4'))\n",
    "quantized_model.model_fp32.conv2_x[1].residual_function[0].register_forward_hook(get_activation('5'))\n",
    "quantized_model.model_fp32.conv2_x[1].residual_function[3].register_forward_hook(get_activation('6'))\n",
    "quantized_model.model_fp32.conv2_x[1].relu.register_forward_hook(get_activation('7'))\n",
    "quantized_model.model_fp32.conv3_x[0].residual_function[0].register_forward_hook(get_activation('8'))\n",
    "quantized_model.model_fp32.conv3_x[0].residual_function[2].register_forward_hook(get_activation('8.2'))\n",
    "quantized_model.model_fp32.conv3_x[0].residual_function[3].register_forward_hook(get_activation('9'))\n",
    "quantized_model.model_fp32.conv3_x[0].relu.register_forward_hook(get_activation('10'))\n",
    "quantized_model.model_fp32.conv5_x[1].relu.register_forward_hook(get_activation('25'))\n",
    "quantized_model.model_fp32.fc.register_forward_hook(get_activation('26'))\n",
    "\n",
    "\n",
    "quantized_model.model_fp32.conv1[3].register_forward_hook(get_activation('maxpool'))\n",
    "output = quantized_model(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "77635d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[19, 27, 39,  ..., 34, 31, 11],\n",
       "          [13,  9, 22,  ...,  8,  8,  5],\n",
       "          [ 7,  4,  1,  ...,  7,  9, 15],\n",
       "          ...,\n",
       "          [ 3,  5,  8,  ...,  6,  5, 13],\n",
       "          [ 3,  7,  7,  ...,  6,  4,  6],\n",
       "          [ 4, 10, 10,  ...,  5,  5,  6]],\n",
       "\n",
       "         [[ 4,  8, 16,  ..., 34, 34, 14],\n",
       "          [ 4,  4,  5,  ..., 34, 34, 10],\n",
       "          [ 9, 10, 11,  ..., 10,  6,  6],\n",
       "          ...,\n",
       "          [ 2,  2,  7,  ...,  3,  5,  5],\n",
       "          [ 2,  2,  2,  ...,  4,  5,  5],\n",
       "          [ 1,  4,  4,  ...,  4,  4,  2]],\n",
       "\n",
       "         [[ 0,  0,  0,  ...,  0,  0,  0],\n",
       "          [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "          [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "          ...,\n",
       "          [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "          [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "          [ 0,  0,  0,  ...,  0,  0,  0]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0,  0,  0,  ...,  0,  0,  0],\n",
       "          [ 2,  0,  0,  ...,  0,  2,  2],\n",
       "          [ 3,  0,  0,  ...,  0,  0,  0],\n",
       "          ...,\n",
       "          [ 0,  6,  7,  ...,  0,  0,  0],\n",
       "          [ 0,  5,  0,  ...,  0,  0,  0],\n",
       "          [ 0,  0,  0,  ...,  0,  0,  0]],\n",
       "\n",
       "         [[10, 17, 17,  ...,  7,  7, 14],\n",
       "          [12, 12, 12,  ..., 11, 25,  6],\n",
       "          [ 7,  9, 10,  ...,  7, 10,  6],\n",
       "          ...,\n",
       "          [10, 15, 15,  ..., 14,  4,  8],\n",
       "          [10, 13, 14,  ...,  6,  4, 10],\n",
       "          [ 3,  5, 11,  ..., 10,  4,  5]],\n",
       "\n",
       "         [[ 0,  2, 10,  ..., 25, 25, 13],\n",
       "          [ 0,  0,  7,  ...,  4,  0,  6],\n",
       "          [11, 14, 10,  ...,  5,  8, 13],\n",
       "          ...,\n",
       "          [ 4,  0,  5,  ..., 12, 12, 10],\n",
       "          [ 4,  2, 10,  ...,  9,  3,  0],\n",
       "          [ 4,  2, 10,  ...,  6,  4,  4]]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation['4'].int_repr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1106001",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict=dict()\n",
    "for i in range(0,27):\n",
    "    output_dict[i]=np.fromfile('partial_output/'+'layer'+str(i)+' output', dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7846fb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantized_input[ 10323 ] 2\n",
      "quant_flatten[ 10323 ] tensor(3, dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "#################quantized input difference\n",
    "comparing_rvx_output= output_dict[0]\n",
    "comparing_torch_output_flatten=activation['conv1'].int_repr().flatten()\n",
    "for i in range(0, len(comparing_rvx_output)):\n",
    "    if(comparing_rvx_output[i]!=comparing_torch_output_flatten[i]):\n",
    "        print(\"quantized_input[\",i,\"]\",comparing_rvx_output[i])\n",
    "        print(\"quant_flatten[\",i,\"]\",comparing_torch_output_flatten[i])\n",
    "               \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "97973232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantized_input[ 72 ] 2\n",
      "quant_flatten[ 72 ] tensor(3, dtype=torch.uint8)\n",
      "quantized_input[ 209 ] 22\n",
      "quant_flatten[ 209 ] tensor(21, dtype=torch.uint8)\n",
      "quantized_input[ 984 ] 1\n",
      "quant_flatten[ 984 ] tensor(2, dtype=torch.uint8)\n",
      "quantized_input[ 1928 ] 4\n",
      "quant_flatten[ 1928 ] tensor(5, dtype=torch.uint8)\n",
      "quantized_input[ 3216 ] 18\n",
      "quant_flatten[ 3216 ] tensor(19, dtype=torch.uint8)\n",
      "quantized_input[ 3345 ] 1\n",
      "quant_flatten[ 3345 ] tensor(2, dtype=torch.uint8)\n",
      "quantized_input[ 3352 ] 10\n",
      "quant_flatten[ 3352 ] tensor(11, dtype=torch.uint8)\n",
      "quantized_input[ 3609 ] 7\n",
      "quant_flatten[ 3609 ] tensor(8, dtype=torch.uint8)\n",
      "quantized_input[ 3920 ] 4\n",
      "quant_flatten[ 3920 ] tensor(3, dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "#################quantized input difference\n",
    "comparing_rvx_output= output_dict[3]\n",
    "comparing_torch_output_flatten=activation['3'].int_repr().flatten()\n",
    "for i in range(0, len(comparing_rvx_output)):\n",
    "    if(comparing_rvx_output[i]!=comparing_torch_output_flatten[i]):\n",
    "        print(\"quantized_input[\",i,\"]\",comparing_rvx_output[i])\n",
    "        print(\"quant_flatten[\",i,\"]\",comparing_torch_output_flatten[i])\n",
    "               \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a1f2b061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3500, size=(), dtype=torch.quint8,\n",
       "       quantization_scheme=torch.per_tensor_affine, scale=0.05000000074505806,\n",
       "       zero_point=0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##intversion\n",
    "weight = quantized_model.model_fp32.conv3_x[0].residual_function[3].weight().int_repr()\n",
    "input=activation['8'].int_repr()\n",
    "padding=torch.nn.ConstantPad2d(1, 0)\n",
    "pad_input=padding(input)\n",
    "#convolution\n",
    "sum=0\n",
    "out_channel=128\n",
    "input_channel_w=4\n",
    "input_channel_h=4\n",
    "channel_size=3\n",
    "input_channel_size=input_channel_w*input_channel_h\n",
    "find_index=12\n",
    "\n",
    "in_channel=int(find_index/input_channel_size)\n",
    "middle_point_x=find_index%input_channel_w\n",
    "\n",
    "middle_point_y=int(int(find_index%input_channel_size)/input_channel_h)\n",
    "\n",
    "for i in range(0,out_channel):\n",
    "    for k in range(0,3):\n",
    "        for j in range(0,3):\n",
    "            sum+=pad_input[in_channel][i][middle_point_y+k][middle_point_x+j]*weight[in_channel][i][k][j]\n",
    "           \n",
    "            print(\"a\",weight[in_channel][i][k][j])\n",
    "            print(\"b\",pad_input[in_channel][i][middle_point_y-1+k][middle_point_x-1+j])\n",
    "            print(\"c\",sum)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "46bdda9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.0987,  0.2168, -0.0154,  0.2475, -0.3167,  0.4579,  0.6514,  0.3452,\n",
       "        -1.2528,  0.0929,  1.4376,  0.6691, -0.0173, -0.0089,  0.2302, -0.5431,\n",
       "        -0.0223,  0.6879,  0.1181, -0.0764, -1.1486,  0.8693,  0.4794, -0.0180,\n",
       "         1.0530,  0.9429, -0.4045,  0.5562,  0.8537,  0.4131,  0.2572, -0.0205,\n",
       "        -1.2007, -0.0248,  0.1395, -0.0155, -0.0113, -0.2503, -0.6267, -0.1959,\n",
       "        -0.2592,  0.4287, -0.2364,  0.0115,  0.3282, -0.0130,  0.5743, -1.0489,\n",
       "        -0.1067,  0.5017,  0.9658,  1.4205,  0.2727,  0.5095, -0.8090, -0.0102,\n",
       "         0.1779,  0.2635,  0.1881,  0.2463,  0.6601,  0.0360,  0.2990,  0.0104],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##intversion_float\n",
    "weight = quantized_model.model_fp32.conv3_x[0].residual_function[3].weight().dequantize()\n",
    "input=activation['8'].dequantize()\n",
    "padding=torch.nn.ConstantPad2d(1, 0)\n",
    "pad_input=padding(input)\n",
    "#convolution\n",
    "sum=0\n",
    "out_channel=128\n",
    "input_channel_w=4\n",
    "input_channel_h=4\n",
    "channel_size=3\n",
    "input_channel_size=input_channel_w*input_channel_h\n",
    "find_index=12\n",
    "\n",
    "in_channel=int(find_index/input_channel_size)\n",
    "middle_point_x=find_index%input_channel_w\n",
    "\n",
    "middle_point_y=int(int(find_index%input_channel_size)/input_channel_h)\n",
    "\n",
    "for i in range(0,out_channel):\n",
    "    for k in range(0,3):\n",
    "        for j in range(0,3):\n",
    "            sum+=pad_input[in_channel][i][middle_point_y+k][middle_point_x+j]*weight[in_channel][i][k][j]\n",
    "           \n",
    "            print(\"a\",weight[in_channel][i][k][j])\n",
    "            print(\"b\",pad_input[in_channel][i][middle_point_y-1+k][middle_point_x-1+j])\n",
    "            print(\"c\",sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3fdfc358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 0, 0,  ..., 0, 0, 0], dtype=torch.uint8)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantized_model.model_fp32.conv3_x[0].residual_function[3].bias().dequantize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17023525",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
