{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a97b4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model.model_fp32.conv1': [['0', '1', '2']], 'model.model_fp32.conv2_x[0].residual_function': [['0', '1', '2'], ['3', '4', '5']], 'model.model_fp32.conv2_x[1].residual_function': [['0', '1', '2'], ['3', '4', '5']], 'model.model_fp32.conv3_x[0].residual_function': [['0', '1', '2'], ['3', '4', '5']], 'model.model_fp32.conv3_x[0].shortcut': [['0', '1', '2']], 'model.model_fp32.conv3_x[1].residual_function': [['0', '1', '2'], ['3', '4', '5']], 'model.model_fp32.conv4_x[0].residual_function': [['0', '1', '2'], ['3', '4', '5']], 'model.model_fp32.conv4_x[0].shortcut': [['0', '1', '2']], 'model.model_fp32.conv4_x[1].residual_function': [['0', '1', '2'], ['3', '4', '5']], 'model.model_fp32.conv5_x[0].residual_function': [['0', '1', '2'], ['3', '4', '5']], 'model.model_fp32.conv5_x[0].shortcut': [['0', '1', '2']], 'model.model_fp32.conv5_x[1].residual_function': [['0', '1', '2'], ['3', '4', '5']]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\win0\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\ao\\quantization\\observer.py:174: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  reduce_range will be deprecated in a future release of PyTorch.\"\n",
      "C:\\Users\\win0\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\ao\\quantization\\observer.py:1109: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  Returning default scale and zero point \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QuantizedResNet18(\n",
       "  (quant): Quantize(scale=tensor([0.0374]), zero_point=tensor([57]), dtype=torch.quint8)\n",
       "  (dequant): DeQuantize()\n",
       "  (model_fp32): ResNet(\n",
       "    (conv1): Sequential(\n",
       "      (0): QuantizedConvReLU2d(3, 64, kernel_size=(7, 7), stride=(2, 2), scale=0.05000000074505806, zero_point=0, padding=(3, 3))\n",
       "      (1): Identity()\n",
       "      (2): Identity()\n",
       "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv2_x): Sequential(\n",
       "      (0): q_BasicBlock(\n",
       "        (residual_function): Sequential(\n",
       "          (0): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.0312686413526535, zero_point=0, padding=(1, 1))\n",
       "          (1): Identity()\n",
       "          (2): Identity()\n",
       "          (3): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.05000000074505806, zero_point=0, padding=(1, 1))\n",
       "          (4): Identity()\n",
       "          (5): Identity()\n",
       "        )\n",
       "        (shortcut): Sequential()\n",
       "        (q_func): QFunctional(\n",
       "          scale=0.05000000074505806, zero_point=0\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): q_BasicBlock(\n",
       "        (residual_function): Sequential(\n",
       "          (0): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.024647517129778862, zero_point=0, padding=(1, 1))\n",
       "          (1): Identity()\n",
       "          (2): Identity()\n",
       "          (3): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.05000000074505806, zero_point=0, padding=(1, 1))\n",
       "          (4): Identity()\n",
       "          (5): Identity()\n",
       "        )\n",
       "        (shortcut): Sequential()\n",
       "        (q_func): QFunctional(\n",
       "          scale=0.05000000074505806, zero_point=0\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (conv3_x): Sequential(\n",
       "      (0): q_BasicBlock(\n",
       "        (residual_function): Sequential(\n",
       "          (0): QuantizedConvReLU2d(64, 128, kernel_size=(3, 3), stride=(2, 2), scale=0.02416195161640644, zero_point=0, padding=(1, 1))\n",
       "          (1): Identity()\n",
       "          (2): Identity()\n",
       "          (3): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.05000000074505806, zero_point=0, padding=(1, 1))\n",
       "          (4): Identity()\n",
       "          (5): Identity()\n",
       "        )\n",
       "        (shortcut): Sequential(\n",
       "          (0): QuantizedConvReLU2d(64, 128, kernel_size=(1, 1), stride=(2, 2), scale=0.05000000074505806, zero_point=0)\n",
       "          (1): Identity()\n",
       "          (2): Identity()\n",
       "        )\n",
       "        (q_func): QFunctional(\n",
       "          scale=0.05000000074505806, zero_point=0\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): q_BasicBlock(\n",
       "        (residual_function): Sequential(\n",
       "          (0): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.02010982111096382, zero_point=0, padding=(1, 1))\n",
       "          (1): Identity()\n",
       "          (2): Identity()\n",
       "          (3): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.05000000074505806, zero_point=0, padding=(1, 1))\n",
       "          (4): Identity()\n",
       "          (5): Identity()\n",
       "        )\n",
       "        (shortcut): Sequential()\n",
       "        (q_func): QFunctional(\n",
       "          scale=0.05000000074505806, zero_point=0\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (conv4_x): Sequential(\n",
       "      (0): q_BasicBlock(\n",
       "        (residual_function): Sequential(\n",
       "          (0): QuantizedConvReLU2d(128, 256, kernel_size=(3, 3), stride=(2, 2), scale=0.021660206839442253, zero_point=0, padding=(1, 1))\n",
       "          (1): Identity()\n",
       "          (2): Identity()\n",
       "          (3): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.05000000074505806, zero_point=0, padding=(1, 1))\n",
       "          (4): Identity()\n",
       "          (5): Identity()\n",
       "        )\n",
       "        (shortcut): Sequential(\n",
       "          (0): QuantizedConvReLU2d(128, 256, kernel_size=(1, 1), stride=(2, 2), scale=0.05000000074505806, zero_point=0)\n",
       "          (1): Identity()\n",
       "          (2): Identity()\n",
       "        )\n",
       "        (q_func): QFunctional(\n",
       "          scale=0.05000000074505806, zero_point=0\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): q_BasicBlock(\n",
       "        (residual_function): Sequential(\n",
       "          (0): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.006181688979268074, zero_point=0, padding=(1, 1))\n",
       "          (1): Identity()\n",
       "          (2): Identity()\n",
       "          (3): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.05000000074505806, zero_point=0, padding=(1, 1))\n",
       "          (4): Identity()\n",
       "          (5): Identity()\n",
       "        )\n",
       "        (shortcut): Sequential()\n",
       "        (q_func): QFunctional(\n",
       "          scale=0.05000000074505806, zero_point=0\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (conv5_x): Sequential(\n",
       "      (0): q_BasicBlock(\n",
       "        (residual_function): Sequential(\n",
       "          (0): QuantizedConvReLU2d(256, 512, kernel_size=(3, 3), stride=(2, 2), scale=0.007224411703646183, zero_point=0, padding=(1, 1))\n",
       "          (1): Identity()\n",
       "          (2): Identity()\n",
       "          (3): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.05000000074505806, zero_point=0, padding=(1, 1))\n",
       "          (4): Identity()\n",
       "          (5): Identity()\n",
       "        )\n",
       "        (shortcut): Sequential(\n",
       "          (0): QuantizedConvReLU2d(256, 512, kernel_size=(1, 1), stride=(2, 2), scale=0.05000000074505806, zero_point=0)\n",
       "          (1): Identity()\n",
       "          (2): Identity()\n",
       "        )\n",
       "        (q_func): QFunctional(\n",
       "          scale=0.05000000074505806, zero_point=0\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): q_BasicBlock(\n",
       "        (residual_function): Sequential(\n",
       "          (0): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.003084570402279496, zero_point=0, padding=(1, 1))\n",
       "          (1): Identity()\n",
       "          (2): Identity()\n",
       "          (3): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.05000000074505806, zero_point=0, padding=(1, 1))\n",
       "          (4): Identity()\n",
       "          (5): Identity()\n",
       "        )\n",
       "        (shortcut): Sequential()\n",
       "        (q_func): QFunctional(\n",
       "          scale=0.05000000074505806, zero_point=0\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): QuantizedLinear(in_features=512, out_features=10, scale=0.2766161859035492, zero_point=0, qscheme=torch.per_channel_affine)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####load quanztized_resnet18\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "sys.path.append(\"..\")\n",
    "from module.layer_fusion_module import *\n",
    "from module.resnet_module import *\n",
    "from module.extract_weight_module import *\n",
    "model_dir = \"saved_models\"\n",
    "model_filename = \"q_resnet18_cifar10.pt\"\n",
    "quantized_model_edited_filename = \"q_resnet18_quantized_cifar10_edited.pt\"\n",
    "fusioned_model_filename = \"q_fusioned_resnet18_cifar10.pt\"\n",
    "quantized_model_filename_jit = \"q_resnet18_quantized_cifar10.pt\"\n",
    "quantized_model_filename = \"q_resnet18_quantized_cifar10.pt\"\n",
    "\n",
    "model_filepath = os.path.join(model_dir, model_filename)\n",
    "quantized_model_filepath = os.path.join(model_dir, quantized_model_filename)\n",
    "quantized_model_filepath_jit = os.path.join(model_dir, quantized_model_filename_jit)\n",
    "quantized_model_edited_filepath = os.path.join(model_dir, quantized_model_edited_filename)\n",
    "\n",
    "num_classes = 10\n",
    "cuda_device = torch.device(\"cuda:0\")\n",
    "cpu_device = torch.device(\"cpu:0\")\n",
    "\n",
    "model = create_model(num_classes=num_classes)\n",
    "model.to(cpu_device)\n",
    "\n",
    "quantized_model = QuantizedResNet18(model_fp32=model)\n",
    "\n",
    "quantization_config = torch.quantization.get_default_qconfig(\"fbgemm\")\n",
    "\n",
    "quantized_model.qconfig = quantization_config\n",
    "fuse_model(quantized_model)\n",
    "torch.quantization.prepare_qat(quantized_model, inplace=True)\n",
    "quantized_model.to(cpu_device)    \n",
    "quantized_model = torch.quantization.convert(quantized_model, inplace=True)\n",
    "#save_torchscript_model(model=quantized_model, model_dir=model_dir, model_filename=quantized_model_filename_jit)\n",
    "#save_model(model=quantized_model, model_dir=model_dir, model_filename=quantized_model_filename)\n",
    "loaded_model=load_model(model=quantized_model, model_filepath=quantized_model_edited_filepath, device='cpu')\n",
    "loaded_model.eval()\n",
    "#save each layer weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a68bfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_name='0001'\n",
    "mean_0=0.485\n",
    "mean_1=0.456\n",
    "mean_2=0.406\n",
    "var_0=0.229\n",
    "var_1=0.224\n",
    "var_2=0.225\n",
    "input_h=32\n",
    "input_w=32\n",
    "input_c=3\n",
    "input_fp_np= np.zeros((1,input_c,input_w,input_h), dtype=np.float32)\n",
    "input_uint8=np.fromfile(input_file_name, dtype=np.uint8)\n",
    "for h in range(0,input_h):\n",
    "    for w in range(0,input_w):\n",
    "        for c in range(0,input_c):\n",
    "            if c==0:\n",
    "                input_fp_np[0][c][h][w]=((input_uint8[c+h*input_w*input_c+w*input_c]/255)-mean_0)/var_0\n",
    "            if c==1:\n",
    "                input_fp_np[0][c][h][w]=((input_uint8[c+h*input_w*input_c+w*input_c]/255)-mean_1)/var_1\n",
    "            if c==2:\n",
    "                input_fp_np[0][c][h][w]=((input_uint8[c+h*input_w*input_c+w*input_c]/255)-mean_2)/var_2\n",
    "input_fp_np_tensor=torch.from_numpy(input_fp_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4183867",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get individual output\n",
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad759d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model.model_fp32.fc.register_forward_hook(get_activation('fc'))\n",
    "quantized_model.quant.register_forward_hook(get_activation('quant'))\n",
    "quantized_model.model_fp32.conv1[0].register_forward_hook(get_activation('conv1'))\n",
    "quantized_model.model_fp32.conv1[3].register_forward_hook(get_activation('maxpool'))\n",
    "output = quantized_model(input_fp_np_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "610469b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4225533"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_fp_np.flatten()[39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "599e3e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([42, 43, 43, 43, 44, 45, 46, 46, 47, 48, 48, 49, 50, 50, 50, 51, 51, 52,\n",
       "        50, 51, 55, 53, 51, 53, 53, 52, 51, 51, 51, 51, 48, 46],\n",
       "       dtype=torch.uint8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation['quant'].int_repr()[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "647951dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[55,  0,  0,  0,  0,  9,  5,  0,  0,  0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation['fc'].int_repr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "904b3f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_input=np.fromfile('0001_quantized_input', dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8386ab25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantized_input[ 27 ] 52\n",
      "quant_flatten[ 27 ] tensor(51, dtype=torch.uint8)\n",
      "quantized_input[ 39 ] 47\n",
      "quant_flatten[ 39 ] tensor(46, dtype=torch.uint8)\n",
      "quantized_input[ 71 ] 46\n",
      "quant_flatten[ 71 ] tensor(45, dtype=torch.uint8)\n",
      "quantized_input[ 81 ] 54\n",
      "quant_flatten[ 81 ] tensor(53, dtype=torch.uint8)\n",
      "quantized_input[ 83 ] 52\n",
      "quant_flatten[ 83 ] tensor(51, dtype=torch.uint8)\n",
      "quantized_input[ 101 ] 45\n",
      "quant_flatten[ 101 ] tensor(44, dtype=torch.uint8)\n",
      "quantized_input[ 155 ] 61\n",
      "quant_flatten[ 155 ] tensor(60, dtype=torch.uint8)\n",
      "quantized_input[ 167 ] 44\n",
      "quant_flatten[ 167 ] tensor(43, dtype=torch.uint8)\n",
      "quantized_input[ 173 ] 44\n",
      "quant_flatten[ 173 ] tensor(43, dtype=torch.uint8)\n",
      "quantized_input[ 177 ] 45\n",
      "quant_flatten[ 177 ] tensor(44, dtype=torch.uint8)\n",
      "quantized_input[ 205 ] 43\n",
      "quant_flatten[ 205 ] tensor(42, dtype=torch.uint8)\n",
      "quantized_input[ 209 ] 47\n",
      "quant_flatten[ 209 ] tensor(46, dtype=torch.uint8)\n",
      "quantized_input[ 237 ] 43\n",
      "quant_flatten[ 237 ] tensor(42, dtype=torch.uint8)\n",
      "quantized_input[ 269 ] 44\n",
      "quant_flatten[ 269 ] tensor(43, dtype=torch.uint8)\n",
      "quantized_input[ 273 ] 49\n",
      "quant_flatten[ 273 ] tensor(48, dtype=torch.uint8)\n",
      "quantized_input[ 307 ] 79\n",
      "quant_flatten[ 307 ] tensor(78, dtype=torch.uint8)\n",
      "quantized_input[ 333 ] 49\n",
      "quant_flatten[ 333 ] tensor(48, dtype=torch.uint8)\n",
      "quantized_input[ 339 ] 94\n",
      "quant_flatten[ 339 ] tensor(93, dtype=torch.uint8)\n",
      "quantized_input[ 353 ] 45\n",
      "quant_flatten[ 353 ] tensor(44, dtype=torch.uint8)\n",
      "quantized_input[ 427 ] 63\n",
      "quant_flatten[ 427 ] tensor(62, dtype=torch.uint8)\n",
      "quantized_input[ 457 ] 84\n",
      "quant_flatten[ 457 ] tensor(83, dtype=torch.uint8)\n",
      "quantized_input[ 459 ] 85\n",
      "quant_flatten[ 459 ] tensor(84, dtype=torch.uint8)\n",
      "quantized_input[ 501 ] 95\n",
      "quant_flatten[ 501 ] tensor(94, dtype=torch.uint8)\n",
      "quantized_input[ 503 ] 93\n",
      "quant_flatten[ 503 ] tensor(92, dtype=torch.uint8)\n",
      "quantized_input[ 531 ] 72\n",
      "quant_flatten[ 531 ] tensor(71, dtype=torch.uint8)\n",
      "quantized_input[ 535 ] 71\n",
      "quant_flatten[ 535 ] tensor(70, dtype=torch.uint8)\n",
      "quantized_input[ 553 ] 91\n",
      "quant_flatten[ 553 ] tensor(90, dtype=torch.uint8)\n",
      "quantized_input[ 565 ] 67\n",
      "quant_flatten[ 565 ] tensor(66, dtype=torch.uint8)\n",
      "quantized_input[ 584 ] 84\n",
      "quant_flatten[ 584 ] tensor(83, dtype=torch.uint8)\n",
      "quantized_input[ 597 ] 43\n",
      "quant_flatten[ 597 ] tensor(42, dtype=torch.uint8)\n",
      "quantized_input[ 617 ] 77\n",
      "quant_flatten[ 617 ] tensor(76, dtype=torch.uint8)\n",
      "quantized_input[ 618 ] 85\n",
      "quant_flatten[ 618 ] tensor(84, dtype=torch.uint8)\n",
      "quantized_input[ 651 ] 79\n",
      "quant_flatten[ 651 ] tensor(80, dtype=torch.uint8)\n",
      "quantized_input[ 653 ] 94\n",
      "quant_flatten[ 653 ] tensor(93, dtype=torch.uint8)\n",
      "quantized_input[ 655 ] 90\n",
      "quant_flatten[ 655 ] tensor(89, dtype=torch.uint8)\n",
      "quantized_input[ 659 ] 64\n",
      "quant_flatten[ 659 ] tensor(63, dtype=torch.uint8)\n",
      "quantized_input[ 737 ] 48\n",
      "quant_flatten[ 737 ] tensor(47, dtype=torch.uint8)\n",
      "quantized_input[ 743 ] 47\n",
      "quant_flatten[ 743 ] tensor(46, dtype=torch.uint8)\n",
      "quantized_input[ 745 ] 47\n",
      "quant_flatten[ 745 ] tensor(46, dtype=torch.uint8)\n",
      "quantized_input[ 775 ] 46\n",
      "quant_flatten[ 775 ] tensor(45, dtype=torch.uint8)\n",
      "quantized_input[ 777 ] 51\n",
      "quant_flatten[ 777 ] tensor(50, dtype=torch.uint8)\n",
      "quantized_input[ 797 ] 44\n",
      "quant_flatten[ 797 ] tensor(43, dtype=torch.uint8)\n",
      "quantized_input[ 817 ] 46\n",
      "quant_flatten[ 817 ] tensor(45, dtype=torch.uint8)\n",
      "quantized_input[ 905 ] 51\n",
      "quant_flatten[ 905 ] tensor(50, dtype=torch.uint8)\n",
      "quantized_input[ 959 ] 43\n",
      "quant_flatten[ 959 ] tensor(42, dtype=torch.uint8)\n",
      "quantized_input[ 969 ] 51\n",
      "quant_flatten[ 969 ] tensor(52, dtype=torch.uint8)\n",
      "quantized_input[ 991 ] 43\n",
      "quant_flatten[ 991 ] tensor(42, dtype=torch.uint8)\n",
      "quantized_input[ 1003 ] 54\n",
      "quant_flatten[ 1003 ] tensor(53, dtype=torch.uint8)\n",
      "quantized_input[ 1005 ] 51\n",
      "quant_flatten[ 1005 ] tensor(50, dtype=torch.uint8)\n",
      "quantized_input[ 1063 ] 62\n",
      "quant_flatten[ 1063 ] tensor(63, dtype=torch.uint8)\n",
      "quantized_input[ 1107 ] 65\n",
      "quant_flatten[ 1107 ] tensor(66, dtype=torch.uint8)\n",
      "quantized_input[ 1123 ] 62\n",
      "quant_flatten[ 1123 ] tensor(63, dtype=torch.uint8)\n",
      "quantized_input[ 1153 ] 63\n",
      "quant_flatten[ 1153 ] tensor(64, dtype=torch.uint8)\n",
      "quantized_input[ 1155 ] 63\n",
      "quant_flatten[ 1155 ] tensor(64, dtype=torch.uint8)\n",
      "quantized_input[ 1171 ] 67\n",
      "quant_flatten[ 1171 ] tensor(68, dtype=torch.uint8)\n",
      "quantized_input[ 1221 ] 64\n",
      "quant_flatten[ 1221 ] tensor(65, dtype=torch.uint8)\n",
      "quantized_input[ 1227 ] 64\n",
      "quant_flatten[ 1227 ] tensor(65, dtype=torch.uint8)\n",
      "quantized_input[ 1261 ] 64\n",
      "quant_flatten[ 1261 ] tensor(65, dtype=torch.uint8)\n",
      "quantized_input[ 1297 ] 63\n",
      "quant_flatten[ 1297 ] tensor(64, dtype=torch.uint8)\n",
      "quantized_input[ 1357 ] 65\n",
      "quant_flatten[ 1357 ] tensor(66, dtype=torch.uint8)\n",
      "quantized_input[ 1367 ] 52\n",
      "quant_flatten[ 1367 ] tensor(53, dtype=torch.uint8)\n",
      "quantized_input[ 1463 ] 88\n",
      "quant_flatten[ 1463 ] tensor(89, dtype=torch.uint8)\n",
      "quantized_input[ 1477 ] 65\n",
      "quant_flatten[ 1477 ] tensor(66, dtype=torch.uint8)\n",
      "quantized_input[ 1481 ] 95\n",
      "quant_flatten[ 1481 ] tensor(96, dtype=torch.uint8)\n",
      "quantized_input[ 1527 ] 92\n",
      "quant_flatten[ 1527 ] tensor(93, dtype=torch.uint8)\n",
      "quantized_input[ 1528 ] 87\n",
      "quant_flatten[ 1528 ] tensor(88, dtype=torch.uint8)\n",
      "quantized_input[ 1533 ] 66\n",
      "quant_flatten[ 1533 ] tensor(67, dtype=torch.uint8)\n",
      "quantized_input[ 1550 ] 102\n",
      "quant_flatten[ 1550 ] tensor(103, dtype=torch.uint8)\n",
      "quantized_input[ 1556 ] 79\n",
      "quant_flatten[ 1556 ] tensor(80, dtype=torch.uint8)\n",
      "quantized_input[ 1557 ] 78\n",
      "quant_flatten[ 1557 ] tensor(79, dtype=torch.uint8)\n",
      "quantized_input[ 1588 ] 78\n",
      "quant_flatten[ 1588 ] tensor(79, dtype=torch.uint8)\n",
      "quantized_input[ 1590 ] 59\n",
      "quant_flatten[ 1590 ] tensor(60, dtype=torch.uint8)\n",
      "quantized_input[ 1610 ] 101\n",
      "quant_flatten[ 1610 ] tensor(102, dtype=torch.uint8)\n",
      "quantized_input[ 1628 ] 63\n",
      "quant_flatten[ 1628 ] tensor(64, dtype=torch.uint8)\n",
      "quantized_input[ 1642 ] 90\n",
      "quant_flatten[ 1642 ] tensor(91, dtype=torch.uint8)\n",
      "quantized_input[ 1677 ] 96\n",
      "quant_flatten[ 1677 ] tensor(97, dtype=torch.uint8)\n",
      "quantized_input[ 1679 ] 92\n",
      "quant_flatten[ 1679 ] tensor(93, dtype=torch.uint8)\n",
      "quantized_input[ 1702 ] 68\n",
      "quant_flatten[ 1702 ] tensor(69, dtype=torch.uint8)\n",
      "quantized_input[ 1706 ] 65\n",
      "quant_flatten[ 1706 ] tensor(66, dtype=torch.uint8)\n",
      "quantized_input[ 1723 ] 64\n",
      "quant_flatten[ 1723 ] tensor(65, dtype=torch.uint8)\n",
      "quantized_input[ 1727 ] 64\n",
      "quant_flatten[ 1727 ] tensor(65, dtype=torch.uint8)\n",
      "quantized_input[ 1767 ] 66\n",
      "quant_flatten[ 1767 ] tensor(67, dtype=torch.uint8)\n",
      "quantized_input[ 1789 ] 61\n",
      "quant_flatten[ 1789 ] tensor(62, dtype=torch.uint8)\n",
      "quantized_input[ 1799 ] 66\n",
      "quant_flatten[ 1799 ] tensor(67, dtype=torch.uint8)\n",
      "quantized_input[ 1830 ] 66\n",
      "quant_flatten[ 1830 ] tensor(67, dtype=torch.uint8)\n",
      "quantized_input[ 1841 ] 60\n",
      "quant_flatten[ 1841 ] tensor(61, dtype=torch.uint8)\n",
      "quantized_input[ 1887 ] 61\n",
      "quant_flatten[ 1887 ] tensor(62, dtype=torch.uint8)\n",
      "quantized_input[ 1907 ] 65\n",
      "quant_flatten[ 1907 ] tensor(66, dtype=torch.uint8)\n",
      "quantized_input[ 1929 ] 65\n",
      "quant_flatten[ 1929 ] tensor(66, dtype=torch.uint8)\n",
      "quantized_input[ 1936 ] 65\n",
      "quant_flatten[ 1936 ] tensor(66, dtype=torch.uint8)\n",
      "quantized_input[ 1951 ] 59\n",
      "quant_flatten[ 1951 ] tensor(60, dtype=torch.uint8)\n",
      "quantized_input[ 1983 ] 58\n",
      "quant_flatten[ 1983 ] tensor(59, dtype=torch.uint8)\n",
      "quantized_input[ 1993 ] 63\n",
      "quant_flatten[ 1993 ] tensor(64, dtype=torch.uint8)\n",
      "quantized_input[ 2029 ] 64\n",
      "quant_flatten[ 2029 ] tensor(65, dtype=torch.uint8)\n",
      "quantized_input[ 2031 ] 67\n",
      "quant_flatten[ 2031 ] tensor(68, dtype=torch.uint8)\n",
      "quantized_input[ 2065 ] 85\n",
      "quant_flatten[ 2065 ] tensor(84, dtype=torch.uint8)\n",
      "quantized_input[ 2075 ] 75\n",
      "quant_flatten[ 2075 ] tensor(74, dtype=torch.uint8)\n",
      "quantized_input[ 2093 ] 82\n",
      "quant_flatten[ 2093 ] tensor(81, dtype=torch.uint8)\n",
      "quantized_input[ 2107 ] 95\n",
      "quant_flatten[ 2107 ] tensor(94, dtype=torch.uint8)\n",
      "quantized_input[ 2125 ] 81\n",
      "quant_flatten[ 2125 ] tensor(80, dtype=torch.uint8)\n",
      "quantized_input[ 2139 ] 105\n",
      "quant_flatten[ 2139 ] tensor(104, dtype=torch.uint8)\n",
      "quantized_input[ 2145 ] 78\n",
      "quant_flatten[ 2145 ] tensor(77, dtype=torch.uint8)\n",
      "quantized_input[ 2175 ] 76\n",
      "quant_flatten[ 2175 ] tensor(75, dtype=torch.uint8)\n",
      "quantized_input[ 2177 ] 78\n",
      "quant_flatten[ 2177 ] tensor(77, dtype=torch.uint8)\n",
      "quantized_input[ 2179 ] 78\n",
      "quant_flatten[ 2179 ] tensor(77, dtype=torch.uint8)\n",
      "quantized_input[ 2207 ] 77\n",
      "quant_flatten[ 2207 ] tensor(75, dtype=torch.uint8)\n",
      "quantized_input[ 2209 ] 79\n",
      "quant_flatten[ 2209 ] tensor(78, dtype=torch.uint8)\n",
      "quantized_input[ 2229 ] 66\n",
      "quant_flatten[ 2229 ] tensor(65, dtype=torch.uint8)\n",
      "quantized_input[ 2241 ] 80\n",
      "quant_flatten[ 2241 ] tensor(79, dtype=torch.uint8)\n",
      "quantized_input[ 2245 ] 81\n",
      "quant_flatten[ 2245 ] tensor(80, dtype=torch.uint8)\n",
      "quantized_input[ 2249 ] 81\n",
      "quant_flatten[ 2249 ] tensor(80, dtype=torch.uint8)\n",
      "quantized_input[ 2269 ] 82\n",
      "quant_flatten[ 2269 ] tensor(81, dtype=torch.uint8)\n",
      "quantized_input[ 2285 ] 84\n",
      "quant_flatten[ 2285 ] tensor(83, dtype=torch.uint8)\n",
      "quantized_input[ 2317 ] 85\n",
      "quant_flatten[ 2317 ] tensor(84, dtype=torch.uint8)\n",
      "quantized_input[ 2391 ] 54\n",
      "quant_flatten[ 2391 ] tensor(53, dtype=torch.uint8)\n",
      "quantized_input[ 2477 ] 90\n",
      "quant_flatten[ 2477 ] tensor(89, dtype=torch.uint8)\n",
      "quantized_input[ 2545 ] 56\n",
      "quant_flatten[ 2545 ] tensor(55, dtype=torch.uint8)\n",
      "quantized_input[ 2555 ] 81\n",
      "quant_flatten[ 2555 ] tensor(80, dtype=torch.uint8)\n",
      "quantized_input[ 2559 ] 76\n",
      "quant_flatten[ 2559 ] tensor(75, dtype=torch.uint8)\n",
      "quantized_input[ 2577 ] 62\n",
      "quant_flatten[ 2577 ] tensor(61, dtype=torch.uint8)\n",
      "quantized_input[ 2589 ] 77\n",
      "quant_flatten[ 2589 ] tensor(76, dtype=torch.uint8)\n",
      "quantized_input[ 2591 ] 83\n",
      "quant_flatten[ 2591 ] tensor(82, dtype=torch.uint8)\n",
      "quantized_input[ 2613 ] 70\n",
      "quant_flatten[ 2613 ] tensor(69, dtype=torch.uint8)\n",
      "quantized_input[ 2652 ] 75\n",
      "quant_flatten[ 2652 ] tensor(76, dtype=torch.uint8)\n",
      "quantized_input[ 2659 ] 69\n",
      "quant_flatten[ 2659 ] tensor(68, dtype=torch.uint8)\n",
      "quantized_input[ 2691 ] 81\n",
      "quant_flatten[ 2691 ] tensor(80, dtype=torch.uint8)\n",
      "quantized_input[ 2751 ] 82\n",
      "quant_flatten[ 2751 ] tensor(81, dtype=torch.uint8)\n",
      "quantized_input[ 2783 ] 82\n",
      "quant_flatten[ 2783 ] tensor(81, dtype=torch.uint8)\n",
      "quantized_input[ 2791 ] 86\n",
      "quant_flatten[ 2791 ] tensor(85, dtype=torch.uint8)\n",
      "quantized_input[ 2793 ] 79\n",
      "quant_flatten[ 2793 ] tensor(78, dtype=torch.uint8)\n",
      "quantized_input[ 2823 ] 85\n",
      "quant_flatten[ 2823 ] tensor(84, dtype=torch.uint8)\n",
      "quantized_input[ 2825 ] 83\n",
      "quant_flatten[ 2825 ] tensor(82, dtype=torch.uint8)\n",
      "quantized_input[ 3001 ] 81\n",
      "quant_flatten[ 3001 ] tensor(80, dtype=torch.uint8)\n",
      "quantized_input[ 3003 ] 80\n",
      "quant_flatten[ 3003 ] tensor(79, dtype=torch.uint8)\n",
      "quantized_input[ 3017 ] 77\n",
      "quant_flatten[ 3017 ] tensor(78, dtype=torch.uint8)\n",
      "quantized_input[ 3025 ] 82\n",
      "quant_flatten[ 3025 ] tensor(81, dtype=torch.uint8)\n",
      "quantized_input[ 3027 ] 82\n",
      "quant_flatten[ 3027 ] tensor(81, dtype=torch.uint8)\n",
      "quantized_input[ 3033 ] 80\n",
      "quant_flatten[ 3033 ] tensor(79, dtype=torch.uint8)\n",
      "quantized_input[ 3035 ] 79\n",
      "quant_flatten[ 3035 ] tensor(78, dtype=torch.uint8)\n",
      "quantized_input[ 3053 ] 83\n",
      "quant_flatten[ 3053 ] tensor(82, dtype=torch.uint8)\n",
      "quantized_input[ 3065 ] 79\n",
      "quant_flatten[ 3065 ] tensor(78, dtype=torch.uint8)\n",
      "quantized_input[ 3067 ] 79\n",
      "quant_flatten[ 3067 ] tensor(78, dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "#################quantized input difference\n",
    "quantized_input=np.fromfile('0001_quantized_input', dtype=np.uint8)\n",
    "quant_flatten=activation['quant'].int_repr().flatten()\n",
    "for i in range(0, len(quantized_input)):\n",
    "    if(quantized_input[i]!=quant_flatten[i]):\n",
    "        print(\"quantized_input[\",i,\"]\",quantized_input[i])\n",
    "        print(\"quant_flatten[\",i,\"]\",quant_flatten[i])\n",
    "               \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "afe18e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "zxc=quantized_model.quant.scale.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a08a44f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03739064], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zxc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daeca0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
