{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13fe9621",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########load mnist saved model\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "sys.path.append(\"..\")\n",
    "from module.lenet5_module import *\n",
    "from module.extract_weight_module import *\n",
    "from module.make_cfg_module import *\n",
    "model_dir = os.getcwd()+'/saved_models'\n",
    "model_filename='le5_saved.pt'\n",
    "model_filepath=model_dir+'/'+model_filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b90c2ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\win0\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\ao\\quantization\\observer.py:174: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  reduce_range will be deprecated in a future release of PyTorch.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0723, Accuracy: 9783/10000 (98%)\n",
      "\n",
      "inference를 할 때 걸린 시간(secs): 6.858540058135986\n"
     ]
    }
   ],
   "source": [
    "###########fusionx load model\n",
    "\n",
    "model_dir = os.getcwd()+'/saved_models'\n",
    "model_filename='le5.pt'\n",
    "model_filepath=model_dir+'/'+'le5.pt'\n",
    "transform = transforms.Compose([\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "dataset1 = datasets.MNIST('../data', train=True, download=True,\n",
    "                              transform = transform)\n",
    "dataset2 = datasets.MNIST('../data', train=False, download=True,\n",
    "                              transform = transform)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset1, batch_size=64)\n",
    "test_loader = torch.utils.data.DataLoader(dataset2, batch_size=1)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model_fp32 = Net()\n",
    "model_fp32.train() # 아래에 진행될 Quantization Aware Training logic이 작동하기 위해서는 모델을 train 모드로 바꿔줘야 한다고 한다.\n",
    "model_fp32.qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')\n",
    "#model_fp32_fused = torch.quantization.fuse_modules(model_fp32, [['conv1', 'relu']])\n",
    "model_fp32_prepared = torch.quantization.prepare_qat(model_fp32)\n",
    "model_fp32_prepared = model_fp32_prepared.to(\"cuda\")\n",
    "model_fp32_prepared = load_model(model=model_fp32_prepared, model_filepath=model_filepath, device='cpu')\n",
    "\n",
    "model_fp32_prepared.eval()\n",
    "model_int8_unfused = torch.quantization.convert(model_fp32_prepared.to('cpu')) #quantized aware training을 floating point로 수행한 model을 quantized integer model로 바꿔준다.\n",
    "\n",
    "\n",
    "\n",
    "model_int8_unfused.eval()\n",
    "\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "start2 = time.time()   \n",
    "count =0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to('cpu'), target.to('cpu') #GPU는 integer형 연산을 지원하지 않으므로 추론 속도를 비교하기 위해서 모델과 data를 모두 cpu로 옮겨줬다.\n",
    "        output = model_int8_unfused(data)\n",
    "        input_data =data\n",
    "        test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "\n",
    "\n",
    "print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)\n",
    "))\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "\n",
    "#print(\"test 이전까지 경과 시간(secs):\",start2-start)\n",
    "print(\"inference를 할 때 걸린 시간(secs):\",end-start2)\n",
    "#print(\"total time elapsed(secs):\", (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42bb1754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[net]\n",
      "\n",
      "batch=1\n",
      "\n",
      "subdivisions=1\n",
      "\n",
      "max_batches=1\n",
      "\n",
      "momentum=0.9\n",
      "\n",
      "decay=0.00005\n",
      "\n",
      "policy=poly\n",
      "\n",
      "power=4\n",
      "\n",
      "learning_rate=0.01\n",
      "\n",
      "angle==1\n",
      "\n",
      "hue==1\n",
      "\n",
      "saturation=1\n",
      "\n",
      "exposure=1\n",
      "\n",
      "aspect=1\n",
      "\n",
      "height=28\n",
      "\n",
      "width=28\n",
      "\n",
      "channels=1\n",
      "\n",
      "quantization_type=1\n",
      "\n",
      "start_check_point=0\n",
      "\n",
      "end_check_point=0\n",
      "\n",
      "input_scale=0.02555669\n",
      "\n",
      "input_zeropoint=17\n",
      "\n",
      "normalize_mean_0=0.1307\n",
      "\n",
      "normalize_mean_1=0.1307\n",
      "\n",
      "normalize_mean_2=0.1307\n",
      "\n",
      "normalize_var_0=0.3081\n",
      "\n",
      "normalize_var_1=0.3081\n",
      "\n",
      "normalize_var_2=0.3081\n",
      "\n",
      "\n",
      "[convolutional]\n",
      "\n",
      "quantization_type=1\n",
      "\n",
      "quantization_layer_scale=0.07234077900648117\n",
      "\n",
      "quantization_layer_zeropoint=53\n",
      "\n",
      "filters=32\n",
      "\n",
      "size=3\n",
      "\n",
      "pad=0\n",
      "\n",
      "stride=1\n",
      "\n",
      "activation=relu\n",
      "\n",
      "\n",
      "[maxpool]\n",
      "\n",
      "quantization_type=1\n",
      "\n",
      "quantization_layer_scale=0.07234077900648117\n",
      "\n",
      "quantization_layer_zeropoint=53\n",
      "\n",
      "size=2\n",
      "\n",
      "pad=0\n",
      "\n",
      "stride=2\n",
      "\n",
      "\n",
      "[convolutional]\n",
      "\n",
      "quantization_type=1\n",
      "\n",
      "quantization_layer_scale=0.1405939757823944\n",
      "\n",
      "quantization_layer_zeropoint=58\n",
      "\n",
      "filters=64\n",
      "\n",
      "size=3\n",
      "\n",
      "pad=0\n",
      "\n",
      "stride=1\n",
      "\n",
      "activation=relu\n",
      "\n",
      "\n",
      "[connected]\n",
      "\n",
      "quantization_type=1\n",
      "\n",
      "quantization_layer_scale=0.22892779111862183\n",
      "\n",
      "quantization_layer_zeropoint=64\n",
      "\n",
      "output=128\n",
      "\n",
      "activation=relu\n",
      "\n",
      "\n",
      "[connected]\n",
      "\n",
      "quantization_type=1\n",
      "\n",
      "quantization_layer_scale=0.24577109515666962\n",
      "\n",
      "quantization_layer_zeropoint=52\n",
      "\n",
      "output=10\n",
      "\n",
      "activation=relu\n",
      "\n",
      "\n",
      "[softmax]\n",
      "\n",
      "groups=1\n",
      "\n",
      "quantization_type=1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_width=28\n",
    "input_height=28\n",
    "input_channel=1\n",
    "mean_list=list()\n",
    "mean_list.append(0.1307)\n",
    "mean_list.append(0.1307)\n",
    "mean_list.append(0.1307)\n",
    "std_list=list()\n",
    "std_list.append(0.3081)\n",
    "std_list.append(0.3081)\n",
    "std_list.append(0.3081)\n",
    "make_cfg_from_pytorch(model_int8_unfused,\"mnist_le.cfg\",input_width,input_height,input_channel,mean_list,std_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8100476a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
